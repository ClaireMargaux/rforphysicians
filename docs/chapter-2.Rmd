---
title: "Chapter 2"
author: "Claire Descombes"
date: "`r Sys.Date()`"
contact: claire.descombes@insel.ch
output:
  html_document:
    toc: yes
    toc_float: yes
    number_sections: yes
    df_print: paged
    theme: paper
    code_folding: show
    math_method: katex
subtitle: "R for physicians"
bibliography: /home/claire/Documents/GitHub/rforphysicians/docs/Rforphysicians.bib
link-citations: yes
editor_options: 
  chunk_output_type: console
knit: (function(input, ...) {rmarkdown::render(input)})
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, 
  warning = FALSE,
  message = FALSE, 
  fig.height = 5,
  fig.width = 6,
  eval = TRUE
)
library(ggplot2)
```

| Author           |                                                                 |
|:-----------------|:----------------------------------------------------------------|
| Name             | Claire Descombes                                                |
| Affiliation      | Universitätsklinik für Neurochirurgie, Inselspital Bern         |
| Degree           | MSc Statistics and Data Science, University of Bern             |
| Contact          | [claire.descombes@insel.ch](mailto:claire.descombes@insel.ch)   |

The reference material for this course, as well as some useful literature to deepen your knowledge of R, can be found at the bottom of the page.

# Importing data

## Working directory

When you get a file from somewhere on your computer (e.g. a dataset), you can either 

* have it in your **R working directory** (see below), in which case you don't need to specify the full path to the file when you import it, 
* or you can get files in different folders, by always **specifying the full path**.

The advantage of putting the files in the folder that contains your script and is set as the working directory is that you can easily move the folder around on your computer without getting any problems with your script: just set the working directory to your source file every time you open it, and you'll be fine.

```{r, eval = FALSE}
# Example
setwd("~/path/to/your/folder/")
data <- read.csv("testdata.csv")
```

The advantage of always giving the full path to a file is that you can get data in different folders on your computer, avoiding things like copying the source data in every folder where you have a corresponding script.

```{r, eval = FALSE}
# Example
data <- read.csv("~/path/to/your/folder/testdata.csv")
```

**Working directory**

To tell R which folder you are working in (e.g., where your data is stored), you have several options:

  + Go to *Session > Set Working Directory > Choose Directory* and select your folder manually.
  + Use `setwd("path/to/your/folder")` in your script.
  + Or, the most convenient for script-based work: go to *Session > Set Working Directory > To Source File Location* to automatically set the working directory to the location of your script.

💡 Tip: To avoid file path errors and keep your project organized, it’s best to store your script and data files in the same folder — or at least place your data files in a subfolder like `data_sets` within your project directory. Then, set that folder as your working directory in R. This ensures that your code can reliably find and save your files.

```{r, eval=FALSE}
getwd()                         # Displays the current working directory
setwd("~/path/to/your/folder")  # Sets the working directory
```

## Import CSV and xlsx data

We will first look at how to import a CSV file into R as a data frame.

CSV stands for Comma-Separated Values. In a `.csv` file, the values are stored as plain text, separated by commas. This is a simple and widely used format for storing tabular data.

After setting your working directory or determining the path to your CSV file, you can use the `read.csv()` function to import the data. This will create a data frame, which is one of the most commonly used structures in R for handling datasets.

```{r, eval=FALSE}
# Import a CSV file into a data frame
dataset <- read.csv("~/path/to/your/folder/data.csv")
```

💡 I recommend using data frames — they are generally easier to work with than matrices, especially for beginners.

Another widely used data format is the Excel file (`.xlsx`). For these, you can use the `readxl` package to import the data:

```{r, eval=FALSE}
# Load the readxl package (after installing it)
library(readxl)

# Read the first sheet of an Excel file
dataset <- read_excel("~/path/to/your/folder/data.xlsx")
```

⚠️ Note: If your file is actually a CSV but mistakenly has a .xlsx extension, you should rename it to .csv and use read.csv() instead. Mixing up formats can lead to import errors.

### Load the NHANES data sets

Let us now look at real data frames to learn how to call or modify their elements. To do this, we will use multiple health data sets from the National Health and Nutrition Examination ([`NHANES`](https://www.cdc.gov/nchs/nhanes/)) Survey from 2011-2012. The survey assessed overall health and nutrition of adults and children in the United States and was conducted by the National Center for Health Statistics (NCHS). The data sets can be found in the [`data_sets` folder](https://github.com/ClaireMargaux/rforphysicians/tree/main/data_sets).

| Dataset               | NHANES Code | Description                                           | CSV File     |
| --------------------- | ----------- | ----------------------------------------------------- | ------------ |
| Demographics          | DEMO\_G     | Age, sex, race/ethnicity, income, education           | `DEMO_G.csv` |
| Blood Pressure        | BPX\_G      | Systolic/diastolic blood pressure, number of readings | `BPX_G.csv`  |
| Body Measures         | BMX\_G      | Height, weight, BMI, waist circumference              | `BMX_G.csv`  |
| Smoking Questionnaire | SMQ\_G      | Smoking habits, exposure to secondhand smoke          | `SMQ_G.csv`  |

```{r}
# Load the necessary CSV files into data frames
demo <- read.csv("/home/claire/Documents/GitHub/rforphysicians/data_sets/DEMO_G.csv") # Demographics (cycle G = 2011–2012)
bpx  <- read.csv("/home/claire/Documents/GitHub/rforphysicians/data_sets/BPX_G.csv") # Blood pressure
bmx  <- read.csv("/home/claire/Documents/GitHub/rforphysicians/data_sets/BMX_G.csv") # Body measures
smq  <- read.csv("/home/claire/Documents/GitHub/rforphysicians/data_sets/SMQ_G.csv") # Smoking questionnaire
```

💡 The codebook for each data set can be accessed either on the [`NCHS website`](https://wwwn.cdc.gov/nchs/nhanes/continuousnhanes/default.aspx?BeginYear=2011) or directly in `R` using the function `nhanesCodebook(nh_table, colname)` from the package `nhanesA` (which I used to download the data). You’ll also find a summary of key variables from each data set at the end of this chapter.

## Exercises

✏️ Exercise on the `NHANES` data sets n°1: import the `demo`, `bpx`, `bmx` and `smq` data sets from the [`data_sets` folder](https://github.com/ClaireMargaux/rforphysicians/tree/main/data_sets) into R.

# Handling data

## Base R vs `tidyverse`

Base R, without any additional packages, already provides many functions that are very handy for data handling. However, some contributed packages make data preparation much easier and more readable.

I’ll introduce two such packages here, before diving into concrete data handling examples. Both are part of a larger and very powerful collection of packages for data science called the `tidyverse`, which I use for nearly all my analyses.

### The pipe

One of the most downloaded contributed extension packages of all times is `magrittr`. It provides a very useful operator, the forward pipe operator `%>%`, which passes the object on its left as the first argument to the function on its right. This is much easier to understand with an example.

```{r, eval=FALSE}
# The easiest way to get magrittr is to install the whole tidyverse
install.packages("tidyverse")
```

```{r}
# Once installed, a package has to be loaded to be used
library(tidyverse)
```

```{r}
library(tidyverse)

# Let's do the same operation twice: once using the pipe, once without

# No pipe:
str(c(1,2,3,4))

# With pipe:
c(1,2,3,4) %>%
  str()

# Not too exciting yet, but consider a more complex case:
summary(log(sqrt(na.omit(c(1, 4, NA, 16, 25)))))

# With the pipe, we can rewrite this more readably:
c(1, 4, NA, 16, 25) %>%
  na.omit() %>%
  sqrt() %>%
  log() %>%
  summary()
```

The pipe helps turn nested function calls into a sequence of simpler, linear steps. This makes code easier to read, write, and debug. The pipe becomes especially powerful when used with functions from the `dplyr` package for data manipulation.

### `dplyr`

Another helpful R package is `dplyr`. It is a grammar of data manipulation, providing a consistent set of verbs that helps solve the most common data manipulation challenges. 

Let’s illustrate this with a simple example. Our goal: Group the cars dataset (contained in base R) by speed groups (e.g. low/medium/high), and for each group, compute (1) the average stopping distance and (2) the number of observations.

```{r}
# Base R (no dplyr, no pipe)

cars$speed_group <- cut(cars$speed, breaks = c(0, 10, 20, 30), 
                        labels = c("Low", "Medium", "High"))

avg_dist <- aggregate(dist ~ speed_group, data = cars, mean)
n_obs <- aggregate(dist ~ speed_group, data = cars, length)
names(n_obs)[2] <- "n"

summary_df <- merge(avg_dist, n_obs, by = "speed_group")
summary_df
```

```{r}
# With dplyr, no pipe:

cars <- mutate(cars, speed_group = cut(speed, breaks = c(0, 10, 20, 30), labels = c("Low", "Medium", "High")))

summary_df <- summarise(group_by(cars, speed_group),
                        avg_dist = mean(dist),
                        n = n())
summary_df
```

```{r}
# With dplyr and the pipe
cars %>%
  mutate(speed_group = cut(speed, breaks = c(0, 10, 20, 30), 
                           labels = c("Low", "Medium","High"))) %>%
  group_by(speed_group) %>%
  summarise(
    avg_dist = mean(dist),
    n = n()
  )
```

💡 `cut(x, ...)` divides the range of `x` into intervals (the `breaks`) and codes the values in x according to which interval they fall. `labels` are the levels of the resulting category. If `labels = FALSE`, simple integer codes are returned instead of a factor.

As you can see, using `dplyr` and the pipe can make your life much easier.

In the following chapter, we’ll use both base R and `tidyverse` functions without always noting which package they belong to. If you're ever unsure, you can check the top-left corner of the function's help page.

```{r, echo=FALSE, out.width = "70%"}
knitr::include_graphics(path = "images/documentation.png")
```

## Accessing elements in data frames

Being able to access elements in a data frame is essential when working with data. Here are some common methods to select specific elements, rows, or columns.

```{r}
# Look at the first respectively last few rows
head(demo)
tail(demo)

# Select columns by name
demo[, c("RIDAGEYR", "RIAGENDR")]  # Selecting age in years and gender
vars <- c("RIDAGEYR", "RIAGENDR")
demo[, vars]  # Alternative using variable `vars`

# Select elements by position
demo[1, 1]  # Access the first element of the first column (the respondent sequence number of the 1st participant)
ind_mat <- cbind(c(1, 3, 5), c(2, 4, 6))
demo[ind_mat]  # Access rows and columns using multiple indices

# Select rows based on a condition
head(demo[, "RIDAGEYR"] > 50)  # Logical condition for age greater than 50
head(!(demo[, "DMDHHSIZ"] > 3))  # Logical negation for total number of people in the household not greater than 3
demo[demo[, "RIDAGEYR"] > 50, ]  # Rows where age > 50
demo[demo[, "DMDHHSIZ"] < 3, ]  # Rows where total number of people in the household greater than 3
demo[demo[, "DMDHHSIZ"] >= 3, ]  # Rows where total number of people in the household greater or equal 3

# Combine logical vectors using "&" (AND), "|" (OR), and "!" (NOT)
demo[(demo[, "RIDAGEYR"] > 50 & demo[, "RIAGENDR"] == "Female"), ]  # Both conditions must be true
demo[(demo[, "DMDHHSIZ"] < 3 | demo[, "RIAGENDR"] == "Male"), ]  # One condition must be true
```

💡 To inspect one column, you can also use the dollar `$` symbol to access a column as a vector.

```{r}
head(demo$RIDAGEYR)  # Returns the age column as a vector
```

💡 You can use the brackets `[]` to select specific rows and columns. Since data frames are bi-dimensional, the first index refers to rows and the second to columns. To select a particular column, you can omit the row index. To select a particular row, omit the column index.

```{r}
head(demo[, "RIDAGEYR"])  # All rows in the age column
demo[1, ]  # Row 1 (all columns)
```

## Basic descriptive statistics

R makes it simple to compute basic descriptive statistics for exploring your dataset. Below are a few useful examples.

### Central tendency: mean and median

```{r}
mean(demo$RIDAGEYR, na.rm = TRUE)                 # Average (mean) age of participants
median(demo$DMDHHSIZ, na.rm = TRUE)               # Median household size
```

💡 The `na.rm` argument in those functions allows for ignoring the NA values.

### Dispersion: standard deviation, min, max, and range

```{r}
sd(demo$RIDAGEYR, na.rm = TRUE)                     # Standard deviation of age
range(demo$DMDHHSZA, na.rm = TRUE)                  # Range of number of young children
min(demo$DMDHRAGE, na.rm = TRUE)                    # Minimum age of household reference person
max(demo$DMDHRAGE, na.rm = TRUE)                    # Maximum age of household reference person
```

### Frequency tables and proportions

```{r}
table(demo$RIAGENDR)                                # Gender distribution
table(demo$DMDHRMAR)                                # Marital status of household reference person
table(demo$AIALANGA)                                # Language of interview
prop.table(table(demo$AIALANGA))                    # Proportional distribution of interview languages
```

### Group-wise summaries

```{r}
aggregate(DMDHRAGE ~ DMDHRMAR, data = demo, FUN = mean, na.rm = TRUE)   # Mean age of household reference person by marital status
aggregate(DMDHHSIZ ~ DMDHRGND, data = demo, FUN = median, na.rm = TRUE) # Median household size by gender of reference person
```

### Full overview

```{r}
summary(demo)[,1:5] # only for the first 5 variables
```

## Modifying elements in data frames

Now, let us assume we want to modify/add/remove one or multiple entries/rows/columns in our data frame. The brackets really come in handy now. In this setting, I recommend defining a new data frame before modifying the original one.

Some examples follow.

```{r}
# Modify one entry:
demo_mod <- demo  # Create a copy to avoid modifying the original data set
demo_mod[1, 1:5]
demo_mod[1, "RIAGENDR"] <- 'Female' # Change gender of the first participant
demo_mod[1, 1:5]

# Modify multiple entries based on a condition:
demo_mod[1:10, 1:5]
demo_mod[!is.na(demo_mod$RIDAGEYR) & demo_mod$RIDAGEYR < 18, ]$RIDAGEYR <- 18  # Set minimum age to 18
demo_mod[1:10, 1:5]
```

## Dealing with NAs

Handling missing data (NAs) is a common task in data analysis. Before deciding how to treat them, it's important to understand where and how often they occur.

```{r}
colSums(is.na(demo))              # Number of NAs per column
sum(complete.cases(demo))         # Number of rows without any NAs
```

💡 `is.na()` returns a logical matrix where TRUE indicates a missing value (NA) and FALSE indicates a non-missing value. `colSums()` takes this logical matrix and sums up the TRUE values (which are treated as 1), giving you the count of missing values for each column.

💡 `complete.cases()` returns a logical vector: TRUE if a row has no missing values, and FALSE otherwise. Using `sum(complete.cases(...))` counts the number of rows with no missing data.

One way to handle missing data is to remove rows containing NAs for the variable(s) you are interested in. This can be appropriate in some cases, but it should be done with care, as it may introduce bias or reduce sample size. We’ll discuss this further in chapter 4.

```{r}
# Remove rows with any missing values in the DMDHRMAR column
demo_DMDHRMAR <- demo[!is.na(demo$DMDHRMAR), ]

# Check for missing values
sum(is.na(demo_DMDHRMAR$DMDHRMAR))
```

You can remove all rows with missing values across any of the columns in the dataset using the function `na.omit()`.

```{r}
# Remove rows with missing values in any column
demo_no_na <- na.omit(demo)

# Check the resulting data frame and its structure
head(demo_no_na)
```

💡 For our `demo` data set, this removes all the rows! Another reminder to be very careful when removing NA values.

## Exercises

✏️ Exercise on the `NHANES` data sets n°2: inspect the structure of the `demo` data set, look at different entries, get familiar with those commands.

✏️ Exercise on the `NHANES` data sets n°3: generate a new data frame selecting only the female patients that are above 18 years old and that took the interview in Spanish.

# Combining data

In practice, data is often spread across multiple data frames that need to be combined. Depending on the structure and goal, there are different ways to combine data frames:

## Column binding with cbind()

Use `cbind()` to add columns side-by-side. The data frames must have the same number of rows.

```{r}
# Extract one column from demo to create an additional data frame with the same number of rows
extra_info <- demo$RIDRETH1

# Combine using cbind
combined_df <- cbind(demo, extra_info)
combined_df[1, ]
```

## Row binding with rbind()

Use `rbind()` to stack data frames vertically. The data frames must have the same column names and types.

```{r}
# Extract one column from demo to create an additional data frame with the same structure (column names and types)
(new_participant <- demo[18,])

# Combine using rbind
extended_df <- rbind(demo, new_participant)
extended_df[nrow(extended_df),]
```

## Merging with merge() (Join)

Use `merge()` to combine data frames based on a common column, similar to SQL joins (see figure below for a reminder on the different types of joins).

```{r}
# Merge two data frames by participant ID `SEQN` (inner join by default)
merged_demo_bpx <- merge(demo, bpx, by = "SEQN")

# In base R, you can use the Reduce() function to iteratively merge a list of data frames
data_list <- list(demo, bpx, bmx) # list of data frames to merge
merged_demo_bpx_bmx <- Reduce(function(x, y) merge(x, y, by = "SEQN"), data_list) # perform an inner join on all data frames by 'SEQN'
``` 

You should specify the type of join you are looking for:

  + Inner join (default): keep only rows with matching `SEQN` in both data frames: `inner_join_df <- merge(demo, bmx, by = "SEQN")`
  + Left (outer) join: keep all rows from `demo` and only matching rows from `bmx`: `left_join_df <- merge(demo, bmx, by = "SEQN", all.x = TRUE)`
  + Right (outer) join: keep all rows from `bmx` and only matching rows from `demo`: `left_join_df <- merge(demo, bmx, by = "SEQN", all.y = TRUE)`
  + Full (outer) join: keep all rows from both `demo` and `bmx`, filling with NA where there are no matches: `full_join_df <- merge(demo, bmx, by = "SEQN", all = TRUE)`

```{r, echo=FALSE, out.width = "50%"}
knitr::include_graphics(path = "images/joins.png")
```

💡 `merge()` in base R is flexible but can be a bit verbose. For simpler syntax, you can also use the `dplyr` package with `left_join()`, `right_join()`, `inner_join()`, and `full_join()`.

## Exercises

✏️ Exercise on the `NHANES` data sets n°4: merge the 4 data sets `demo`, `bpx`, `bmx` and `smq` into a single data set `merged_nhanes` by performing an inner join on the `SEQN` ID and using the `dplyr` package.

# Saving data

You can save data sets in different formats, depending on how you want to use them later:

  + CSV – human-readable and widely supported (e.g. by Excel, Python, etc.)
  + RDS – R-specific format for saving a single R object (more compact than CSV, preserves data types)
  + RData – used to save multiple R objects into a single file

Let us save a data frame in all those different formats.

```{r, eval=FALSE}
# Specify the directory for the data
directory <- "~/Documents/GitHub/rforphysicians/data_sets/"

# Save as CSV
write.csv(merged_demo_bpx_bmx, file = file.path(directory,"merged_demo_bpx_bmx.csv"), row.names = FALSE)

# Save as RDS (recommended for re-loading in R)
saveRDS(merged_demo_bpx_bmx, file = file.path(directory,"merged_demo_bpx_bmx.rds"))

# Save as RData (can contain multiple objects)
save(merged_demo_bpx_bmx, file = file.path(directory,"merged_demo_bpx_bmx.RData"))
```

💡 `file.path()` constructs the path to a file from components in a platform-independent way. It concatenates paths and filenames, and automatically uses the correct file separator (/ on Unix/macOS, \\ on Windows), making your code more robust and portable.

💡 You can load these later using:

   + `read.csv("merged_demo_bpx_bmx.csv")`
   + `readRDS("merged_demo_bpx_bmx.rds")`
   + `load("merged_demo_bpx_bmx.RData")`
   
## Exercises

✏️ Exercise on the `NHANES` data sets n°5: Save the data frame resulting from Exercise n°4 in your working directory in both .csv and .rds formats.

# Solutions to the exercises

Please not that those are only examples, there are always many ways to solve the same task!

☑️ Exercise on the `NHANES` data sets n°1: If you have trouble importing the data sets into R, let me know, I'd be glad to help.

☑️ Exercise on the `NHANES` data sets n°2: Did you manage to select a specific column you were interested in? Were you able to check how many men and women are included in the data set? Here are a few examples of operations you can use to explore the data set.

```{r}
# View the first few rows of the dataset
head(demo)

# Display the names of all columns
names(demo)

# View all unique values in the "AIALANGA" (Interview Language) column
unique(demo$AIALANGA)

# Count how many men and women are in the dataset
table(demo$RIAGENDR)

# Get a quick statistical summary of a few columns
summary(demo[,c('RIDAGEYR','DMDHHSZA','DMDHRAGE')])

# View the number of missing values in each column
colSums(is.na(demo))

# Calculate the average age
mean(demo$RIDAGEYR, na.rm = TRUE)
```

☑️ Exercise on the `NHANES` data sets n°3:

```{r}
# Filter the dataset to include only female patients that are above 18 years old and that took the interview in Spanish.
demo_filtered <- demo[demo$RIAGENDR == "Female" & 
                      demo$RIDAGEYR > 17 & 
                      !is.na(demo$AIALANGA) & demo$AIALANGA == "Spanish", ]
ind <- c('RIAGENDR', 'RIDAGEYR', 'AIALANGA')
demo_filtered[, ind]
```

💡 Note: When filtering on a variable that contains missing values (e.g., `AIALANGA`), you must explicitly exclude NAs using `!is.na(...)`. This is because comparisons like demo$AIALANGA == "Spanish" return NA for missing values, not FALSE, so those rows aren't properly excluded from the subset.

☑️ Exercise on the `NHANES` data sets n°4:

```{r, eval=FALSE}
# If necessary, install the dplyr package
install.packages("dplyr")
```

```{r}
# Load the dplyr package
library(dplyr)

# Merge the datasets using inner joins by SEQN
data_list <- list(demo, bpx, bmx, smq)
merged_nhanes <- Reduce(function(x, y) inner_join(x, y, by = "SEQN"), data_list)
```

☑️ Exercise on the `NHANES` data sets n°5:

```{r}
# Save the merged dataset in your working directory
# Click on Session > Set Working Directory > To Source File Location, or use file.path()
write.csv(merged_nhanes, "merged_nhanes.csv", row.names = FALSE)
saveRDS(merged_nhanes, "merged_nhanes.rds")
```

# NHANES data sets

Here are listed some of the variables from the NHANES data sets.

## Demographics (DEMO_G)

| Variable Name | Description                                           |
| ------------- | ----------------------------------------------------- |
| RIDAGEYR      | Participant's age in years                            |
| RIAGENDR      | Participant's gender                                  |
| DMDHHSIZ      | Total number of people in the household               |
| DMDHHSZA      | Number of children aged 5 or younger in the household |
| DMDHRAGE      | Age of the household reference person                 |
| DMDHRMAR      | Marital status of the household reference person      |
| DMDHRGND      | Gender of the household reference person              |
| AIALANGA      | Language of the interview                             |

## Blood Pressure (BPX_G)

| Variable Name | Description                                        |
| ------------- | -------------------------------------------------- |
| BPXSY1        | Systolic blood pressure (first reading) in mm Hg   |
| BPXSY2        | Systolic blood pressure (second reading) in mm Hg  |
| BPXSY3        | Systolic blood pressure (third reading) in mm Hg   |
| BPXDI1        | Diastolic blood pressure (first reading) in mm Hg  |
| BPXDI2        | Diastolic blood pressure (second reading) in mm Hg |
| BPXDI3        | Diastolic blood pressure (third reading) in mm Hg  |
| BPXPULS       | Pulse rate (beats per minute)                      |
| BPXPLS        | 60-second pulse (30-second pulse multiplied by 2)  |
| BPXPTY        | Pulse type (e.g., regular or irregular)            |
| BPXML1        | Maximum inflation level (mm Hg)                    |

## Body Measures (BMX_G)

| Variable Name | Description                  |
| ------------- | ---------------------------- |
| BMXWT         | Weight (kg)                  |
| BMXHT         | Standing height (cm)         |
| BMXBMI        | Body Mass Index (kg/m²)      |
| BMXWAIST      | Waist circumference (cm)     |
| BMXHIP        | Hip circumference (cm)       |
| BMXARML       | Upper arm length (cm)        |
| BMXARMC       | Upper arm circumference (cm) |
| BMXLEG        | Upper leg length (cm)        |

## Smoking Questionnaire (SMQ_G)

| Variable Name | Description                                 |
| ------------- | ------------------------------------------- |
| SMQ020        | Smoked at least 100 cigarettes in life      |
| SMQ040        | Do you now smoke cigarettes?                |
| SMQ050Q       | Average number of cigarettes smoked per day |
| SMD030        | Age when first smoked cigarettes regularly  |
| SMD070        | Age when last smoked cigarettes regularly   |
| SMQ680        | Smoked cigars in the past 5 days            |
| SMQ690        | Smoked pipes in the past 5 days             |
| SMQ700        | Smoked chewing tobacco in the past 5 days   |
| SMQ710        | Smoked snuff in the past 5 days             |

\newpage

# References

---
nocite: '@*'
...